# ğŸš€ NASA Turbofan Engine Predictive Maintenance & Anomaly Detection

## ğŸ“Œ Project Overview
This project focuses on *predictive maintenance and anomaly detection* for turbofan engines using *machine learning (Random Forest, XGBoost, SVM)* and *deep learning (LSTM, RNN)* models.

We leverage the *NASA CMAPSS dataset, which contains **sensor data from 100+ engines operating under different conditions. Our goal is to predict the **Remaining Useful Life (RUL)* of engines and detect anomalies before failure occurs.

---

## ğŸ“‚ Dataset: NASA C-MAPSS

The *C-MAPSS (Commercial Modular Aero-Propulsion System Simulation) dataset* consists of *run-to-failure* sensor readings from *turbofan engines* under varying operational conditions.

### ğŸ”¹ *Dataset Structure*
Each engine has *21 sensor readings* collected over time until failure. The dataset includes:
- *Unit Number (unit_nr)* â†’ Unique engine ID.
- *Time (time_cycles)* â†’ Operational cycle count.
- *Operational Settings (setting_1, setting_2, setting_3)* â†’ Control parameters affecting engine conditions.
- *21 Sensor Measurements (s_1 to s_21)* â†’ Temperature, pressure, speed, and efficiency indicators.
- *Remaining Useful Life (RUL)* â†’ Number of cycles before failure.

### ğŸ”¹ *Preprocessing Steps*
âœ” *Feature Selection* â†’ Identified most relevant sensors using *correlation analysis*.
âœ” *Normalization* â†’ Scaled features for better model performance.
âœ” *Time-Series Transformation* â†’ Used *sliding window approach* for LSTM models.

---

## ğŸ“’ Implemented Notebooks

### ğŸ§  *1ï¸âƒ£ Predictive Maintenance using LSTM*
ğŸ“Œ *Goal:* Build a *Long Short-Term Memory (LSTM) neural network* to predict *RUL*.
ğŸ”¹ *Techniques Used:*
âœ” Time-series data transformation for sequential learning.
âœ” Multi-layer *LSTM model* with dropout to prevent overfitting.
âœ” Optimized *batch size, learning rate, and epochs* for performance.

---

### ğŸŒ² *2ï¸âƒ£ Anomaly Detection using Random Forest*
ğŸ“Œ *Goal:* Detect anomalies in sensor data using *Random Forest* classification.
ğŸ”¹ *Techniques Used:*
âœ” *Feature importance analysis* to identify key contributing sensors.
âœ” *Random Forest model* to classify normal vs. failing engines.
âœ” *Hyperparameter tuning* (n_estimators, max_depth) for improved accuracy.

---

### ğŸ¤– *3ï¸âƒ£ Implementation of 10 Different Models for Best RUL Prediction*
ğŸ“Œ *Goal:* Compare *10 different regression models* to find the best one for RUL prediction.
ğŸ”¹ *Implemented Models:*
1ï¸âƒ£ *Linear Regression*
2ï¸âƒ£ *Lasso Regression*
3ï¸âƒ£ *Ridge Regression*
4ï¸âƒ£ *Decision Tree*
5ï¸âƒ£ *Random Forest*
6ï¸âƒ£ *Support Vector Regressor (SVR)*
7ï¸âƒ£ *Gradient Boosting Regressor*
8ï¸âƒ£ *Artificial Neural Network (ANN)*
9ï¸âƒ£ *Recurrent Neural Network (RNN)*
ğŸ”Ÿ *Long Short-Term Memory (LSTM)*

ğŸ”¹ *Findings:*
âœ” *SVR & LSTM outperformed traditional models.*
âœ” *Random Forest achieved strong baseline results.*
âœ” *Decision Trees overfitted, showing high training accuracy but poor test performance.*

---

## ğŸ“Š *Model Comparison & Results*

| Model                          | MSE   | RMSE  | RÂ² Score | Accuracy (%) |
|--------------------------------|-------|-------|----------|-------------|
| *Linear Regression*          | 6992  | 83.6  | 3.08     | 56          |
| *Lasso Regression*           | 6841  | 82.7  | 2.99     | 56          |
| *Ridge Regression*           | 6992  | 83.6  | 3.08     | 56          |
| *Decision Tree*              | 10101 | 100.5 | 4.89     | 100 (Overfitting) |
| *Random Forest*              | 7279  | 85.3  | 3.25     | 94          |
| *Support Vector Regressor*   | 5770  | 75.9  | 2.36     | 57 (Best Traditional) |
| *Gradient Boosting*          | 6968  | 83.4  | 3.06     | 60          |
| *Artificial Neural Network*  | 7341  | 85.6  | 3.29     | 72.89       |
| *Recurrent Neural Network*   | 6648.1| 81.53 | 2.88     | 100         |
| *LSTM (Deep Learning)*       | 6711.7| 81.92 | 2.91     | 100 (Best Deep Learning) |

ğŸ“Œ *Key Findings:*
âœ” *Support Vector Regressor (SVR) had the lowest RMSE (75.9), making it the best traditional model.*
âœ” *LSTM showed promising results with time-series learning capabilities.*
âœ” *Decision Tree overfitted, performing poorly on unseen data.*
âœ” *Random Forest provided a strong baseline with 94% accuracy.*

---

## ğŸ¨ Streamlit Application for RUL Prediction

We developed a *Streamlit web application* that allows users to *input sensor data* and predict the *Remaining Useful Life (RUL)* of an engine in real-time. The application:
âœ” Loads the *trained Random Forest model* for predictions.
âœ” Accepts *manual input or CSV uploads*.
âœ” Provides *interactive visualizations* for better interpretability.

To run the application:
bash
streamlit run app.py


---

## ğŸ› ï¸ *Installation & Usage*

### ğŸ“¥ *Setup the Environment*
bash
git clone https://github.com/your-username/turbofan-predictive-maintenance.git  
cd turbofan-predictive-maintenance  
pip install -r requirements.txt  


### ğŸƒ *Run Notebooks*
Execute Jupyter Notebooks in the notebooks/ directory:
bash
jupyter notebook


---

## ğŸš€ *Future Improvements*
âœ” *Experiment with XGBoost & LightGBM* for better predictive performance.  
âœ” *Implement Transformer models for time-series forecasting.*  
âœ” *Deploy model using Flask or FastAPI for real-time predictions.*  
âœ” *Feature engineering to improve sensor data representation.*  

---

## ğŸ“œ *References*
- ğŸ“„ [NASA C-MAPSS Dataset](https://data.nasa.gov/Aerospace/NASA-C-MAPSS-Dataset/)  
- ğŸ“„ [Predictive Maintenance & Machine Learning](https://arxiv.org/pdf/1709.05603.pdf)  
- ğŸ“„ [LSTMs for Time Series Prediction](https://www.tensorflow.org/tutorials/structured_data/time_series)  

---

## ğŸ¤ *Contributors*
ğŸ‘¨â€ğŸ’» *Siddhant Shetty* ([@your-github](https://github.com/Siddhantshetty)) 
ğŸ‘¨â€ğŸ’» *Varun Putta* ([@your-github](https://github.com/varunputta1511))  
ğŸ“© Feel free to *open issues & pull requests* for improvements!
